{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fchrisbrantner%2Ffiles%2F2019%2F02%2Fimdb-freedive-1200x549.jpg)\n",
    "\n",
    "Sentiment analysis is part of the Natural Language Processing (NLP) techniques that consists in extracting emotions related to some raw texts. This is usually used on social media posts and customer reviews in order to automatically understand if some users are positive or negative and why. The goal of this study is to show how sentiment analysis can be performed using python. Here are some of the main libraries we will use:\n",
    "\n",
    "NLTK: the most famous python module for NLP techniques\n",
    "Gensim: a topic-modelling and vector space modelling toolkit\n",
    "Scikit-learn: the most used python machine learning library\n",
    "We will use here some movie reviews data. Each customer’s review is composed of a textual feedback of the customer’s experience about the movie. The data can be found here:\n",
    "https://drive.google.com/open?id=1vc-zzz1VmSCDCqEIoJiZjFbn-qXjX18e\n",
    "\n",
    "For each textual review, we want to predict if it corresponds to a good review (the customer is happy) or to a bad one (the customer is not satisfied). In order to simplify the problem we will split those into two sentimental categories:\n",
    "\n",
    "- bad reviews have sentiment value 0\n",
    "- good reviews have sentiment value 1\n",
    "The challenge here is to be able to predict this information using only the raw textual data from the review.\n",
    "Let’s get it started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Library for cleaning data\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "import string\n",
    "import re\n",
    "translator = str.maketrans(\" \",\" \", string.punctuation)\n",
    "\n",
    "# Library for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# library for training model\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# library for evaluate model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Library for save model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             review  sentiment\n",
       "0  5814_8  With all this stuff going down at the moment w...          1\n",
       "1  2381_9  \\The Classic War of the Worlds\\\" by Timothy Hi...          1\n",
       "2  7759_3  The film starts with a manager (Nicholas Bell)...          0\n",
       "3  3630_4  It must be assumed that those who praised this...          0\n",
       "4  9495_8  Superbly trashy and wondrously unpretentious 8...          1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import movie dataset \n",
    "# this movie include movie review from IMDB\n",
    "\n",
    "movie_df = pd.read_csv('movie_review.csv', sep=\"\\t\")\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11278\n",
       "0    11222\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check balance of the dataset\n",
    "\n",
    "movie_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a balance between the number of positive and negative reviews.\n",
    "\n",
    "### For this project, we use the review as `Input` and sentiment as `Label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We could observed that the review has a lot of punctuation/stop-words. So we should go ahead and clean it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Phase 2: Clean data\n",
    "\n",
    "> **The cleaning phase has 2 step:** \n",
    "- Remove punctuation/stop-words \n",
    "- stemming words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cleaning function\n",
    "\n",
    "def clean_review(review):\n",
    "    review = review.lower()\n",
    "    review = re.sub(re.compile(\"[<.*>]\"), '', review)\n",
    "    review = review.translate(translator)\n",
    "    words = word_tokenize(review)\n",
    "    \n",
    "    clean_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            clean_words.append(stemmer.stem(word))\n",
    "    return ' '.join(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classic war world timothi hine entertain film obvious goe great effort length faith recreat h g well classic book mr hine succeed watch film appreci fact standard predict hollywood fare come everi year eg spielberg version tom cruis slightest resembl book obvious everyon look differ thing movi envis amateur critic look critic everyth other rate movi import baseslik entertain peopl never agre critic enjoy effort mr hine put faith hg well classic novel found entertain made easi overlook critic perceiv shortcom'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cleaning function\n",
    "\n",
    "clean_review(movie_df['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply cleaning function to movie_df['review]\n",
    "\n",
    "movie_df.loc[:, 'review'] = movie_df['review'].apply(lambda x: clean_review(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaning-dataset for later use\n",
    "\n",
    "movie_df.to_csv('imdb_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Phase 3: Training model\n",
    "\n",
    "> **The training phase has 3 step:** \n",
    "- Split the dataset into train and test sets using train_test_split.\n",
    "- Vectorize the Input of train and test sets using TF-IDF\n",
    "- Train model using LogisticRegression() and RandomForest() on train set and predict on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets.\n",
    "\n",
    "X = movie_df['review']\n",
    "y = movie_df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the Input of train and test sets using TF-IDF\n",
    "\n",
    "tf_idf = TfidfVectorizer()\n",
    "tf_idf_X_train = tf_idf.fit_transform(X_train)\n",
    "tf_idf_X_test = tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tf-idf model\n",
    "\n",
    "pickle.dump(tf_idf, open('tf_idf', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model using LogisticRegression()\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(tf_idf_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.87      0.89      2199\n",
      "          1       0.88      0.91      0.89      2301\n",
      "\n",
      "avg / total       0.89      0.89      0.89      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call predict on test set and print classification_report\n",
    "\n",
    "lr_prediction = lr_model.predict(tf_idf_X_test)\n",
    "print(classification_report(y_test, lr_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We got a good result here. Now let's try RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.86      0.83      2199\n",
      "          1       0.86      0.80      0.83      2301\n",
      "\n",
      "avg / total       0.83      0.83      0.83      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do the same with RandomForest\n",
    "\n",
    "rf_model = RandomForestClassifier(50)\n",
    "rf_model.fit(tf_idf_X_train, y_train)\n",
    "rf_prediction = rf_model.predict(tf_idf_X_test)\n",
    "print(classification_report(y_test, rf_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest get lower f1-score than LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we gonna stack the result of two model in order to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.87      0.88      2199\n",
      "          1       0.88      0.89      0.89      2301\n",
      "\n",
      "avg / total       0.88      0.88      0.88      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_prediction = (rf_model.predict_proba(tf_idf_X_test)[:,1] + lr_model.predict_proba(tf_idf_X_test)[:,1])//1\n",
    "print(classification_report(y_test, all_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Phase 3.1: Training model using doc2vec for Vectorized review\n",
    "\n",
    "_Intead of using TF-IDF_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/368/1*keqyBCQ5FL6A7DZLrXamvQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import doc2vec from gensim library\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vectorized-model\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d), tags=[str(i)]) for i, _d in enumerate(movie_df['review'])]\n",
    "\n",
    "max_epochs = 50\n",
    "vec_size = 300\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# train vectorized-model and save for later use\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectorized-model\n",
    "\n",
    "doc2vec_model = Doc2Vec.load('d2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized training Input and test Input\n",
    "\n",
    "d2v_X_train = []\n",
    "d2v_X_test = []\n",
    "\n",
    "for review in X_train:\n",
    "    d2v_X_train.append(doc2vec_model.infer_vector(word_tokenize(review)))\n",
    "\n",
    "for review in X_test:\n",
    "    d2v_X_test.append(doc2vec_model.infer_vector(word_tokenize(review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83      2199\n",
      "          1       0.83      0.84      0.83      2301\n",
      "\n",
      "avg / total       0.83      0.83      0.83      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model using LogisticRegression(), call predict and print classification_report\n",
    "\n",
    "d2v_lr_model = LogisticRegression()\n",
    "d2v_lr_model.fit(d2v_X_train, y_train)\n",
    "d2v_lr_prediction = d2v_lr_model.predict(d2v_X_test)\n",
    "print(classification_report(y_test, d2v_lr_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88      2199\n",
      "          1       0.89      0.88      0.89      2301\n",
      "\n",
      "avg / total       0.88      0.88      0.88      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stack 3 model \n",
    "\n",
    "final_prediction = (rf_model.predict(tf_idf_X_test) + lr_model.predict(tf_idf_X_test) + d2v_lr_model.predict(d2v_X_test))//2\n",
    "print(classification_report(y_test, final_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Phase 4: Training model on all sample and predict label on no_label dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X_train_all and y_train_all for TF-IDF\n",
    "\n",
    "tf_idf_final = TfidfVectorizer()\n",
    "X_train_all = tf_idf_final.fit_transform(X)\n",
    "y_train_all = y\n",
    "\n",
    "# create X_train_all and y_train_all for doc2vec\n",
    "d2v_X_train_all = np.r_[d2v_X_train, d2v_X_test]\n",
    "d2v_y_train_all = np.r_[y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tf-idf final model\n",
    "\n",
    "pickle.dump(tf_idf_final, open('tf_idf_final', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using TF-IDF\n",
    "\n",
    "lr_model_final = LogisticRegression().fit(X_train_all, y_train_all)\n",
    "rf_model_final = RandomForestClassifier(50).fit(X_train_all, y_train_all)\n",
    "\n",
    "# Train using doc2vec\n",
    "\n",
    "d2v_lr_model_final = LogisticRegression().fit(d2v_X_train_all, d2v_y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 3 model\n",
    "\n",
    "pickle.dump(lr_model_final, open('lr_final', 'wb'))\n",
    "pickle.dump(rf_model_final, open('rf_final', 'wb'))\n",
    "pickle.dump(d2v_lr_model_final, open('d2v_lr_final', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 3 model\n",
    "\n",
    "rf_model = pickle.load(open('rf_final', 'rb'))\n",
    "lr_model = pickle.load(open('lr_final', 'rb'))\n",
    "d2v_lr_model = pickle.load(open('d2v_lr_final', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Vectorized-model\n",
    "\n",
    "tf_idf_final = pickle.load(open('tf_idf_final', 'rb'))\n",
    "doc2vec_model = Doc2Vec.load('d2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10633_1</td>\n",
       "      <td>I watched this video at a friend's house. I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4489_1</td>\n",
       "      <td>`The Matrix' was an exciting summer blockbuste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3304_10</td>\n",
       "      <td>This movie is one among the very few Indian mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3350_3</td>\n",
       "      <td>The script for this movie was probably found i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1119_1</td>\n",
       "      <td>Even if this film was allegedly a joke in resp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             review\n",
       "0  10633_1  I watched this video at a friend's house. I'm ...\n",
       "1   4489_1  `The Matrix' was an exciting summer blockbuste...\n",
       "2  3304_10  This movie is one among the very few Indian mo...\n",
       "3   3350_3  The script for this movie was probably found i...\n",
       "4   1119_1  Even if this film was allegedly a joke in resp..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load need-predicted dataset\n",
    "\n",
    "no_label_df = pd.read_csv('movie_review_noLabel.csv', sep='\\t')\n",
    "no_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean review (again)\n",
    "\n",
    "X_nolabel_train = no_label_df['review'].apply(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize Input data using TF-IDF\n",
    "\n",
    "X_nolabel_train_final = tf_idf_final.transform(X_nolabel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize Input data using doc2vec\n",
    "\n",
    "d2v_X_nolabel_train_final = []\n",
    "for review in X_nolabel_train:\n",
    "    d2v_X_nolabel_train_final.append(doc2vec_model.infer_vector(word_tokenize(review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict labels using results from 3 models \n",
    "\n",
    "no_label_all_predict = (rf_model.predict(X_nolabel_train_final) + lr_model.predict(X_nolabel_train_final) + d2v_lr_model.predict(d2v_X_nolabel_train_final))//2\n",
    "no_label_all_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10633_1</td>\n",
       "      <td>I watched this video at a friend's house. I'm ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4489_1</td>\n",
       "      <td>`The Matrix' was an exciting summer blockbuste...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3304_10</td>\n",
       "      <td>This movie is one among the very few Indian mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3350_3</td>\n",
       "      <td>The script for this movie was probably found i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1119_1</td>\n",
       "      <td>Even if this film was allegedly a joke in resp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             review  sentiment\n",
       "0  10633_1  I watched this video at a friend's house. I'm ...          0\n",
       "1   4489_1  `The Matrix' was an exciting summer blockbuste...          0\n",
       "2  3304_10  This movie is one among the very few Indian mo...          1\n",
       "3   3350_3  The script for this movie was probably found i...          0\n",
       "4   1119_1  Even if this film was allegedly a joke in resp...          0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add predicted labels back to no-label dataset \n",
    "\n",
    "no_label_df['sentiment'] = no_label_all_predict\n",
    "no_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the labeled-dataset for later use\n",
    "\n",
    "no_label_df.to_csv('label_submit.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
